{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZgJPO-bvo4B",
        "outputId": "c141c8d0-6498-4df1-a737-f7c2c2bbd974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/forrestbao/pyeeg.git\n",
            "  Cloning https://github.com/forrestbao/pyeeg.git to /tmp/pip-req-build-mrf33r_o\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/forrestbao/pyeeg.git /tmp/pip-req-build-mrf33r_o\n",
            "  Resolved https://github.com/forrestbao/pyeeg.git to commit a6c18bb093e4748f9d9c208535a6ae024a0802b8\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from pyeeg==0.4.4) (1.25.2)\n",
            "Building wheels for collected packages: pyeeg\n",
            "  Building wheel for pyeeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyeeg: filename=pyeeg-0.4.4-py2.py3-none-any.whl size=28111 sha256=d79f77fac100b74f550827746ecff58bbd23099c89c571885cdd865385328dc2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-at9__a90/wheels/a8/c4/1a/cee09dcc12a11620066d35ace42e3c1e3bfbcc1db3a0ce7788\n",
            "Successfully built pyeeg\n",
            "Installing collected packages: pyeeg\n",
            "Successfully installed pyeeg-0.4.4\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/forrestbao/pyeeg.git\n",
        "import numpy as np\n",
        "import pyeeg as pe\n",
        "import pickle as pickle\n",
        "import pandas as pd\n",
        "import math\n",
        "from sklearn import svm\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as8z-Xaeu99V"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWlMgzPBwGwF",
        "outputId": "b7d326ef-d1c9-4de4-fa33-d3999cade60e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCMT74t9wowG"
      },
      "outputs": [],
      "source": [
        "band = [4,8,12,16,25,45] #5 bands\n",
        "#channel = [1,2,3,4,6,11,13,17,19,20,21,25,29,31] #14 Channels chosen to fit Emotiv Epoch+\n",
        "channel = [2,7,13,24,29] #5 Channels chosen to fit Emotiv Ensight\n",
        "window_size = 256 #Averaging band power of 2 sec\n",
        "step_size = 16 #Each 0.125 sec update once\n",
        "sample_rate = 128 #Sampling rate of 128 Hz\n",
        "subjectList = [str(i).zfill(2) for i in range(1, 33)]\n",
        "#List of subjects"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "def FFT_Processing(sub, channel, band, window_size, step_size, sample_rate):\n",
        "    meta = []\n",
        "    with open(os.path.join('/content/drive/MyDrive/data_preprocessed_python', 's' + sub + '.dat'), 'rb') as file:\n",
        "        subject = pickle.load(file, encoding='latin1') # resolve the python 2 data problem by encoding: latin1\n",
        "\n",
        "        for i in range(0, 40):\n",
        "            data = subject[\"data\"][i]\n",
        "            labels = subject[\"labels\"][i]\n",
        "            start = 0\n",
        "\n",
        "            while start + window_size < data.shape[1]:\n",
        "                meta_data = [] # meta vector for analysis\n",
        "                for j in channel:\n",
        "                    X = data[j-1][start: start + window_size] # Slice raw data over 2 sec, at interval of 0.125 sec\n",
        "                    Y = pe.bin_power(X, band, sample_rate) # FFT over 2 sec of channel j, in seq of theta, alpha, low beta, high beta, gamma\n",
        "                    meta_data.extend(Y[0])\n",
        "\n",
        "                meta_array = [np.array(meta_data), labels] # Use list to contain meta_data and labels\n",
        "                meta.append(meta_array) # Append the list to meta\n",
        "                start += step_size\n",
        "\n",
        "    # Convert meta to an array if needed right before saving\n",
        "    np.save(os.path.join('/content/drive/MyDrive/data_preprocessed_python/Deap5_FFT', 's' + sub), np.array(meta, dtype=object), allow_pickle=True)"
      ],
      "metadata": {
        "id": "b2Hcxtc1edfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWcHt5X2xDfw"
      },
      "source": [
        "for subjects in subjectList:\n",
        "    FFT_Processing (subjects, channel, band, window_size, step_size, sample_rate)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJfG_qw8WyXO"
      },
      "source": [
        "\n",
        "data_training = []\n",
        "label_training = []\n",
        "data_testing = []\n",
        "label_testing = []\n",
        "\n",
        "for subjects in subjectList:\n",
        "\n",
        "    with open('/content/drive/MyDrive/data_preprocessed_python/Deap5_FFT/s' + subjects + '.npy', 'rb') as file:\n",
        "      sub = np.load(file,allow_pickle=True)\n",
        "      for i in range (0,sub.shape[0]):\n",
        "        if i % 5 == 0:\n",
        "          data_testing.append(sub[i][0])\n",
        "          label_testing.append(sub[i][1])\n",
        "        else:\n",
        "          data_training.append(sub[i][0])\n",
        "          label_training.append(sub[i][1])\n",
        "\n",
        "np.save('/content/drive/MyDrive/data_preprocessed_python/Deap5_FFT/data_training', np.array(data_training), allow_pickle=True, fix_imports=True)\n",
        "np.save('/content/drive/MyDrive/data_preprocessed_python/Deap5_FFT/label_training', np.array(label_training), allow_pickle=True, fix_imports=True)\n",
        "print(\"training dataset:\", np.array(data_training).shape, np.array(label_training).shape)\n",
        "\n",
        "np.save('/content/drive/MyDrive/data_preprocessed_python/Deap5_FFT/data_testing', np.array(data_testing), allow_pickle=True, fix_imports=True)\n",
        "np.save('/content/drive/MyDrive/data_preprocessed_python/Deap5_FFT/label_testing', np.array(label_testing), allow_pickle=True, fix_imports=True)\n",
        "print(\"testing dataset:\", np.array(data_testing).shape, np.array(label_testing).shape)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
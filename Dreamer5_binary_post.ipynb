{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Activation, AvgPool1D, Dense, Conv1D, Flatten, Dropout, Input, BatchNormalization, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D\n",
        "from keras.optimizers import Adam\n",
        "#from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from scipy import signal\n",
        "import pickle as pkl"
      ],
      "metadata": {
        "id": "8-9dGr41nRfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import signal\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical  # Sử dụng thư viện phù hợp để chuyển đổi nhãn sang one-hot\n",
        "selected_channels = [channel_indices['AF3'], channel_indices['AF4'], channel_indices['T7'], channel_indices['T8']]\n",
        "def load_data(eeg_band=None):\n",
        "    data = []\n",
        "    val_label = []\n",
        "    aro_label = []\n",
        "    dom_label = []\n",
        "    base_path = '/content/drive/MyDrive/DREAMER DATA/Process_Data'  # Đường dẫn cơ sở cho dữ liệu\n",
        "\n",
        "    for person in range(1, 24):\n",
        "        print('Person No. ' + str(person))\n",
        "        person_path = f\"{base_path}/person{person}\"\n",
        "\n",
        "        # Tải các nhãn\n",
        "        valence = pd.read_csv(f\"{person_path}/eeg_labels/valence.csv\", header=None).values.ravel()\n",
        "        arousal = pd.read_csv(f\"{person_path}/eeg_labels/arousal.csv\", header=None).values.ravel()\n",
        "        dominance = pd.read_csv(f\"{person_path}/eeg_labels/dominance.csv\", header=None).values.ravel()\n",
        "\n",
        "        # Chuyển đổi nhãn sang lớp phân loại dựa trên ngưỡng\n",
        "        valence = (valence > 3).astype(int)\n",
        "        arousal = (arousal > 3).astype(int)\n",
        "        dominance = (dominance > 3).astype(int)\n",
        "\n",
        "        # Xử lý và phân đoạn dữ liệu EEG\n",
        "        for i in range(1, 19):\n",
        "            eeg = pd.read_csv(f\"{person_path}/eeg_samples/eeg{i}.csv\", header=None).values\n",
        "            # Chỉ lấy dữ liệu từ các kênh đã chọn\n",
        "            eeg = eeg[:, selected_channels]\n",
        "            num, den = signal.butter(4, bands[eeg_band], 'band')  # Tạo bộ lọc Butterworth\n",
        "            eeg = signal.filtfilt(num, den, eeg, axis=0)\n",
        "\n",
        "            scaler = StandardScaler().fit(eeg)\n",
        "            eeg = scaler.transform(eeg)\n",
        "\n",
        "            # Phân đoạn dữ liệu\n",
        "            start = 0\n",
        "            while start + 1280 < eeg.shape[0]:\n",
        "                end = start + 1280\n",
        "                data.append(eeg[start:end])\n",
        "                val_label.append(valence[i-1])  # Nhãn cho mỗi phân đoạn\n",
        "                aro_label.append(arousal[i-1])\n",
        "                dom_label.append(dominance[i-1])\n",
        "                start += 256  # Độ chồng lấp\n",
        "\n",
        "    data = np.array(data, dtype=np.float32)\n",
        "    val_label = to_categorical(np.array(val_label, dtype=np.int8))\n",
        "    aro_label = to_categorical(np.array(aro_label, dtype=np.int8))\n",
        "    dom_label = to_categorical(np.array(dom_label, dtype=np.int8))\n",
        "\n",
        "    return data, val_label, aro_label, dom_label\n",
        "\n",
        "# Các biến để định nghĩa băng tần\n",
        "bands = {\n",
        "    'delta': [0.5/64, 4/64],\n",
        "    'theta': [4/64, 8/64],\n",
        "    'alpha': [8/64, 14/64],\n",
        "    'beta': [14/64, 30/64],\n",
        "    'gamma': [30/64, 50/64]\n",
        "}\n"
      ],
      "metadata": {
        "id": "pTJ_B_glrkbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "FOLD = 10  # Number of folds\n",
        "eeg_band = 'theta'  # EEG band name\n",
        "\n",
        "# Assuming load_data is imported and correctly implemented as discussed\n",
        "data, valence, arousal, dominance = load_data(eeg_band)  # Loading processed data\n",
        "\n",
        "nb_samples = data.shape[0]  # Number of samples\n",
        "factor = nb_samples // FOLD  # Kth fold by this factor\n",
        "\n",
        "# Shuffling data\n",
        "shuffler = np.random.permutation(nb_samples)\n",
        "data = data[shuffler]\n",
        "valence = valence[shuffler]\n",
        "arousal = arousal[shuffler]\n",
        "dominance = dominance[shuffler]\n",
        "\n",
        "# Now data and labels are shuffled and ready to be split into folds.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRRfeuI6pI-P",
        "outputId": "ac8e039f-8182-4cbf-a9d8-216aaee15371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Person No. 1\n",
            "Person No. 2\n",
            "Person No. 3\n",
            "Person No. 4\n",
            "Person No. 5\n",
            "Person No. 6\n",
            "Person No. 7\n",
            "Person No. 8\n",
            "Person No. 9\n",
            "Person No. 10\n",
            "Person No. 11\n",
            "Person No. 12\n",
            "Person No. 13\n",
            "Person No. 14\n",
            "Person No. 15\n",
            "Person No. 16\n",
            "Person No. 17\n",
            "Person No. 18\n",
            "Person No. 19\n",
            "Person No. 20\n",
            "Person No. 21\n",
            "Person No. 22\n",
            "Person No. 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HT9_T6B5MZkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv1D, AvgPool1D, BatchNormalization, SpatialDropout1D, GlobalAvgPool1D, Dropout, Dense, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Định nghĩa Input ở bên ngoài hàm get_model\n",
        "eeg_input = Input(shape=(window_size, 4), name='eeg_input')\n",
        "\n",
        "def get_CNN(eeg_input):\n",
        "    x = Conv1D(filters=32, kernel_size=5, strides=2, padding='valid', activation='relu', name='conv1')(eeg_input)\n",
        "    # Thêm các layer tiếp theo như trước\n",
        "    x = Conv1D(filters=512, kernel_size=3, strides=1, padding='valid', activation='relu', name='conv8')(x)\n",
        "    x = GlobalAvgPool1D(name='global_pool1')(x)\n",
        "    x = BatchNormalization(name='batch_norm4')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(64)(x)\n",
        "    x = Activation('tanh')(x)\n",
        "    x = Dense(8)(x)\n",
        "    x = Activation('tanh')(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    return x\n",
        "\n",
        "def get_model(eeg_input):\n",
        "    x = get_CNN(eeg_input)\n",
        "    out = Dense(classes, activation='softmax', name='output')(x)  # Output layer\n",
        "    model = Model(inputs=eeg_input, outputs=out)  # Tạo instance của Model\n",
        "    adam = Adam(learning_rate=1e-3)  # Adam optimizer\n",
        "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['categorical_accuracy'])  # Biên dịch model\n",
        "    model.summary()\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Q5YKVoXnwe6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "yRA9Kpo6wiWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Khởi tạo biến kết quả\n",
        "val_res = {'accuracy': [], 'confusion_matrix': []}\n",
        "FOLD = 10\n",
        "nb_samples = data.shape[0]\n",
        "kfold = KFold(n_splits=FOLD, shuffle=True, random_state=42)  # K-fold Cross-Validation\n",
        "\n",
        "for train_index, test_index in kfold.split(data):\n",
        "    X_train, X_test = data[train_index], data[test_index]\n",
        "    val_train, val_test = valence[train_index], valence[test_index]\n",
        "\n",
        "    model = get_model(eeg_input)  # Tạo mô hình mới\n",
        "    history = model.fit(X_train, val_train, epochs=100, batch_size=256, shuffle=True)\n",
        "\n",
        "    # In kết quả huấn luyện\n",
        "    print(\"Training Loss:\", history.history['loss'][-1])\n",
        "    print(\"Training Accuracy:\", history.history['categorical_accuracy'][-1])\n",
        "\n",
        "    # Đánh giá mô hình trên tập kiểm tra\n",
        "    loss, accuracy = model.evaluate(X_test, val_test)\n",
        "    print(\"Test Loss:\", loss)\n",
        "    print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "    # Dự đoán và tính toán confusion matrix\n",
        "    pred = model.predict(X_test)\n",
        "    cm = confusion_matrix(val_test.argmax(axis=1), pred.argmax(axis=1))\n",
        "    val_res['accuracy'].append(accuracy)\n",
        "    val_res['confusion_matrix'].append(cm)\n",
        "    print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# Lưu kết quả vào file\n",
        "file_path = '/content/drive/MyDrive/DREAMER DATA/Process_Data/Dreamer_valence_' + str(eeg_band) + '.pkl'\n",
        "with open(file_path, 'wb') as f:\n",
        "    pkl.dump(val_res, f)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZCVpEm6cv7A7",
        "outputId": "dccae938-da2c-400a-9d65-04e9fd35cd61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " eeg_input (InputLayer)      [(None, 1280, 4)]         0         \n",
            "                                                                 \n",
            " conv1 (Conv1D)              (None, 638, 32)           672       \n",
            "                                                                 \n",
            " conv8 (Conv1D)              (None, 636, 512)          49664     \n",
            "                                                                 \n",
            " global_pool1 (GlobalAverag  (None, 512)               0         \n",
            " ePooling1D)                                                     \n",
            "                                                                 \n",
            " batch_norm4 (BatchNormaliz  (None, 512)               2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 64)                32832     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 64)                0         \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 8)                 520       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 8)                 0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85754 (334.98 KB)\n",
            "Trainable params: 84730 (330.98 KB)\n",
            "Non-trainable params: 1024 (4.00 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "144/144 [==============================] - 10s 52ms/step - loss: 0.6747 - categorical_accuracy: 0.5894\n",
            "Epoch 2/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.6564 - categorical_accuracy: 0.6179\n",
            "Epoch 3/100\n",
            "144/144 [==============================] - 7s 49ms/step - loss: 0.6468 - categorical_accuracy: 0.6340\n",
            "Epoch 4/100\n",
            "144/144 [==============================] - 7s 49ms/step - loss: 0.6377 - categorical_accuracy: 0.6382\n",
            "Epoch 5/100\n",
            "144/144 [==============================] - 7s 49ms/step - loss: 0.6280 - categorical_accuracy: 0.6497\n",
            "Epoch 6/100\n",
            "144/144 [==============================] - 7s 49ms/step - loss: 0.6220 - categorical_accuracy: 0.6572\n",
            "Epoch 7/100\n",
            "144/144 [==============================] - 7s 49ms/step - loss: 0.6105 - categorical_accuracy: 0.6670\n",
            "Epoch 8/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.6017 - categorical_accuracy: 0.6770\n",
            "Epoch 9/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.5961 - categorical_accuracy: 0.6830\n",
            "Epoch 10/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.5881 - categorical_accuracy: 0.6895\n",
            "Epoch 11/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.5807 - categorical_accuracy: 0.6944\n",
            "Epoch 12/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.5736 - categorical_accuracy: 0.6994\n",
            "Epoch 13/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.5648 - categorical_accuracy: 0.7072\n",
            "Epoch 14/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.5619 - categorical_accuracy: 0.7060\n",
            "Epoch 15/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.5559 - categorical_accuracy: 0.7136\n",
            "Epoch 16/100\n",
            "144/144 [==============================] - 7s 49ms/step - loss: 0.5482 - categorical_accuracy: 0.7216\n",
            "Epoch 17/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.5425 - categorical_accuracy: 0.7265\n",
            "Epoch 18/100\n",
            "144/144 [==============================] - 7s 49ms/step - loss: 0.5397 - categorical_accuracy: 0.7264\n",
            "Epoch 19/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.5359 - categorical_accuracy: 0.7297\n",
            "Epoch 20/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.5279 - categorical_accuracy: 0.7338\n",
            "Epoch 21/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.5192 - categorical_accuracy: 0.7388\n",
            "Epoch 22/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.5153 - categorical_accuracy: 0.7442\n",
            "Epoch 23/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.5121 - categorical_accuracy: 0.7470\n",
            "Epoch 24/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.5055 - categorical_accuracy: 0.7500\n",
            "Epoch 25/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.5041 - categorical_accuracy: 0.7524\n",
            "Epoch 26/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.4938 - categorical_accuracy: 0.7573\n",
            "Epoch 27/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.4904 - categorical_accuracy: 0.7613\n",
            "Epoch 28/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.4845 - categorical_accuracy: 0.7636\n",
            "Epoch 29/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.4790 - categorical_accuracy: 0.7680\n",
            "Epoch 30/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.4758 - categorical_accuracy: 0.7689\n",
            "Epoch 31/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.4685 - categorical_accuracy: 0.7741\n",
            "Epoch 32/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.4660 - categorical_accuracy: 0.7760\n",
            "Epoch 33/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.4625 - categorical_accuracy: 0.7768\n",
            "Epoch 34/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.4571 - categorical_accuracy: 0.7810\n",
            "Epoch 35/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.4545 - categorical_accuracy: 0.7830\n",
            "Epoch 36/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.4456 - categorical_accuracy: 0.7911\n",
            "Epoch 37/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.4426 - categorical_accuracy: 0.7909\n",
            "Epoch 38/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.4408 - categorical_accuracy: 0.7924\n",
            "Epoch 39/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.4370 - categorical_accuracy: 0.7954\n",
            "Epoch 40/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.4320 - categorical_accuracy: 0.7976\n",
            "Epoch 41/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.4249 - categorical_accuracy: 0.8026\n",
            "Epoch 42/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.4200 - categorical_accuracy: 0.8041\n",
            "Epoch 43/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.4202 - categorical_accuracy: 0.8023\n",
            "Epoch 44/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.4110 - categorical_accuracy: 0.8084\n",
            "Epoch 45/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.4098 - categorical_accuracy: 0.8131\n",
            "Epoch 46/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.4061 - categorical_accuracy: 0.8119\n",
            "Epoch 47/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3984 - categorical_accuracy: 0.8178\n",
            "Epoch 48/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3986 - categorical_accuracy: 0.8154\n",
            "Epoch 49/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3990 - categorical_accuracy: 0.8168\n",
            "Epoch 50/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3937 - categorical_accuracy: 0.8200\n",
            "Epoch 51/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3870 - categorical_accuracy: 0.8245\n",
            "Epoch 52/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3866 - categorical_accuracy: 0.8224\n",
            "Epoch 53/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3824 - categorical_accuracy: 0.8253\n",
            "Epoch 54/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3793 - categorical_accuracy: 0.8270\n",
            "Epoch 55/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3780 - categorical_accuracy: 0.8292\n",
            "Epoch 56/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3692 - categorical_accuracy: 0.8347\n",
            "Epoch 57/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3695 - categorical_accuracy: 0.8339\n",
            "Epoch 58/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3643 - categorical_accuracy: 0.8373\n",
            "Epoch 59/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3607 - categorical_accuracy: 0.8398\n",
            "Epoch 60/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3611 - categorical_accuracy: 0.8397\n",
            "Epoch 61/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3581 - categorical_accuracy: 0.8381\n",
            "Epoch 62/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3553 - categorical_accuracy: 0.8429\n",
            "Epoch 63/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3488 - categorical_accuracy: 0.8446\n",
            "Epoch 64/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3442 - categorical_accuracy: 0.8474\n",
            "Epoch 65/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3455 - categorical_accuracy: 0.8478\n",
            "Epoch 66/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3454 - categorical_accuracy: 0.8472\n",
            "Epoch 67/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3359 - categorical_accuracy: 0.8526\n",
            "Epoch 68/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3333 - categorical_accuracy: 0.8547\n",
            "Epoch 69/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3308 - categorical_accuracy: 0.8537\n",
            "Epoch 70/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3268 - categorical_accuracy: 0.8572\n",
            "Epoch 71/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3256 - categorical_accuracy: 0.8577\n",
            "Epoch 72/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3228 - categorical_accuracy: 0.8574\n",
            "Epoch 73/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3219 - categorical_accuracy: 0.8601\n",
            "Epoch 74/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3214 - categorical_accuracy: 0.8614\n",
            "Epoch 75/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3094 - categorical_accuracy: 0.8676\n",
            "Epoch 76/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3175 - categorical_accuracy: 0.8624\n",
            "Epoch 77/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3088 - categorical_accuracy: 0.8673\n",
            "Epoch 78/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3103 - categorical_accuracy: 0.8658\n",
            "Epoch 79/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3034 - categorical_accuracy: 0.8674\n",
            "Epoch 80/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3010 - categorical_accuracy: 0.8708\n",
            "Epoch 81/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.3010 - categorical_accuracy: 0.8697\n",
            "Epoch 82/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.2971 - categorical_accuracy: 0.8702\n",
            "Epoch 83/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.2990 - categorical_accuracy: 0.8709\n",
            "Epoch 84/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.2932 - categorical_accuracy: 0.8724\n",
            "Epoch 85/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.2914 - categorical_accuracy: 0.8771\n",
            "Epoch 86/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.2885 - categorical_accuracy: 0.8777\n",
            "Epoch 87/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.2870 - categorical_accuracy: 0.8784\n",
            "Epoch 88/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.2859 - categorical_accuracy: 0.8782\n",
            "Epoch 89/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.2845 - categorical_accuracy: 0.8794\n",
            "Epoch 90/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.2796 - categorical_accuracy: 0.8792\n",
            "Epoch 91/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.2759 - categorical_accuracy: 0.8845\n",
            "Epoch 92/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.2748 - categorical_accuracy: 0.8842\n",
            "Epoch 93/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.2752 - categorical_accuracy: 0.8843\n",
            "Epoch 94/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.2723 - categorical_accuracy: 0.8851\n",
            "Epoch 95/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.2695 - categorical_accuracy: 0.8840\n",
            "Epoch 96/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.2683 - categorical_accuracy: 0.8863\n",
            "Epoch 97/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.2645 - categorical_accuracy: 0.8902\n",
            "Epoch 98/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.2654 - categorical_accuracy: 0.8882\n",
            "Epoch 99/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.2599 - categorical_accuracy: 0.8910\n",
            "Epoch 100/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.2606 - categorical_accuracy: 0.8916\n",
            "Training Loss: 0.26057618856430054\n",
            "Training Accuracy: 0.89158034324646\n",
            "128/128 [==============================] - 1s 4ms/step - loss: 0.3284 - categorical_accuracy: 0.8596\n",
            "Test Loss: 0.3283577263355255\n",
            "Test Accuracy: 0.8595890402793884\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "Confusion Matrix:\n",
            " [[2166  276]\n",
            " [ 298 1348]]\n",
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " eeg_input (InputLayer)      [(None, 1280, 4)]         0         \n",
            "                                                                 \n",
            " conv1 (Conv1D)              (None, 638, 32)           672       \n",
            "                                                                 \n",
            " conv8 (Conv1D)              (None, 636, 512)          49664     \n",
            "                                                                 \n",
            " global_pool1 (GlobalAverag  (None, 512)               0         \n",
            " ePooling1D)                                                     \n",
            "                                                                 \n",
            " batch_norm4 (BatchNormaliz  (None, 512)               2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 64)                32832     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 64)                0         \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 8)                 520       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 8)                 0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85754 (334.98 KB)\n",
            "Trainable params: 84730 (330.98 KB)\n",
            "Non-trainable params: 1024 (4.00 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "144/144 [==============================] - 9s 53ms/step - loss: 0.6909 - categorical_accuracy: 0.5751\n",
            "Epoch 2/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.6619 - categorical_accuracy: 0.6090\n",
            "Epoch 3/100\n",
            "144/144 [==============================] - 7s 48ms/step - loss: 0.6476 - categorical_accuracy: 0.6249\n",
            "Epoch 4/100\n",
            "144/144 [==============================] - 7s 49ms/step - loss: 0.6374 - categorical_accuracy: 0.6392\n",
            "Epoch 5/100\n",
            "144/144 [==============================] - 7s 49ms/step - loss: 0.6293 - categorical_accuracy: 0.6475\n",
            "Epoch 6/100\n",
            "144/144 [==============================] - 7s 49ms/step - loss: 0.6218 - categorical_accuracy: 0.6544\n",
            "Epoch 7/100\n",
            "144/144 [==============================] - 7s 49ms/step - loss: 0.6136 - categorical_accuracy: 0.6644\n",
            "Epoch 8/100\n",
            "144/144 [==============================] - 7s 49ms/step - loss: 0.6050 - categorical_accuracy: 0.6695\n",
            "Epoch 9/100\n",
            "144/144 [==============================] - 7s 49ms/step - loss: 0.6012 - categorical_accuracy: 0.6722\n",
            "Epoch 10/100\n",
            "144/144 [==============================] - 7s 49ms/step - loss: 0.5928 - categorical_accuracy: 0.6809\n",
            "Epoch 11/100\n",
            "144/144 [==============================] - 7s 49ms/step - loss: 0.5865 - categorical_accuracy: 0.6858\n",
            "Epoch 12/100\n",
            "144/144 [==============================] - 7s 49ms/step - loss: 0.5821 - categorical_accuracy: 0.6909\n",
            "Epoch 13/100\n",
            "102/144 [====================>.........] - ETA: 2s - loss: 0.5788 - categorical_accuracy: 0.6922"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-af9ee71f7f54>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meeg_input\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Tạo mô hình mới\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# In kết quả huấn luyện\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d032GGgBLUO_",
        "outputId": "6e1717dd-5d0b-4a24-e7d0-4ac1d8df3e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': [0.6796363592147827, 0.6256839036941528, 0.5998565554618835, 0.5802474021911621, 0.5617167353630066, 0.5385253429412842, 0.5163530707359314, 0.49033159017562866, 0.46594810485839844, 0.44155779480934143, 0.4175613224506378, 0.3976639211177826, 0.37849175930023193, 0.3594135642051697, 0.34315407276153564, 0.32249388098716736, 0.31331783533096313, 0.29782161116600037, 0.2848975360393524, 0.27292975783348083, 0.2632759213447571, 0.2553407847881317, 0.2409684658050537, 0.2328132688999176, 0.22740982472896576, 0.21585184335708618, 0.21196343004703522, 0.20380455255508423, 0.19598229229450226, 0.18937943875789642, 0.18226902186870575, 0.17491918802261353, 0.17238061130046844, 0.16943109035491943, 0.16574928164482117, 0.16032801568508148, 0.1491883248090744, 0.14827701449394226, 0.14574892818927765, 0.14172005653381348, 0.14209069311618805, 0.13243931531906128, 0.13433803617954254, 0.12666553258895874, 0.12903709709644318, 0.1278049796819687, 0.11795727163553238, 0.11393167078495026, 0.1184224784374237, 0.11273329704999924, 0.11405421793460846, 0.10965946316719055, 0.10934990644454956, 0.1067708283662796, 0.10711749643087387, 0.1032637283205986, 0.09757018834352493, 0.10095914453268051, 0.09900559484958649, 0.0931263342499733, 0.09337735176086426, 0.09459137171506882, 0.09271107614040375, 0.09538082033395767, 0.08983302861452103, 0.08517046272754669, 0.08266279101371765, 0.08758734911680222, 0.08199051767587662, 0.08544447273015976, 0.07655783742666245, 0.08236178010702133, 0.08234377205371857, 0.07938828319311142, 0.0766168087720871, 0.07623947411775589, 0.07371558248996735, 0.07405287027359009, 0.06998023390769958, 0.07277526706457138, 0.07436272501945496, 0.07335138320922852, 0.07165603339672089, 0.07017084211111069, 0.07090473920106888, 0.06570592522621155, 0.06785178184509277, 0.06615262478590012, 0.06589197367429733, 0.06433165818452835, 0.059840962290763855, 0.06350691616535187, 0.06599774211645126, 0.06305207312107086, 0.062016330659389496, 0.06442788988351822, 0.06374034285545349, 0.06344261020421982, 0.06542320549488068, 0.0607273243367672], 'categorical_accuracy': [0.5957643389701843, 0.6490769982337952, 0.676372230052948, 0.6946143507957458, 0.711796224117279, 0.730826735496521, 0.7456433773040771, 0.7639670372009277, 0.7801973819732666, 0.7962917685508728, 0.8090150356292725, 0.8208139538764954, 0.8312535881996155, 0.8415300250053406, 0.8510181307792664, 0.8623548746109009, 0.8653725981712341, 0.8733382225036621, 0.8795367479324341, 0.8857080936431885, 0.8901394605636597, 0.892368733882904, 0.9004159569740295, 0.9035967588424683, 0.9051464200019836, 0.9121061563491821, 0.9132751822471619, 0.9192289710044861, 0.9213223457336426, 0.9255906343460083, 0.9273849129676819, 0.9313541650772095, 0.932115375995636, 0.9319522380828857, 0.9343446493148804, 0.9374439120292664, 0.9418753385543823, 0.9416306614875793, 0.9437512159347534, 0.9457358121871948, 0.9470135569572449, 0.9474757313728333, 0.9506837129592896, 0.9516896605491638, 0.9502487778663635, 0.9517983794212341, 0.9548704624176025, 0.9566919207572937, 0.9550879597663879, 0.9575075507164001, 0.9566647410392761, 0.9584862589836121, 0.9582415819168091, 0.958730936050415, 0.9596009254455566, 0.9618573784828186, 0.9626185894012451, 0.9610418081283569, 0.9630807638168335, 0.9647935032844543, 0.96645188331604, 0.9646304249763489, 0.9652284979820251, 0.9641138315200806, 0.9665878415107727, 0.9681918025016785, 0.9687899351119995, 0.96778404712677, 0.9692249298095703, 0.9694696068763733, 0.9718891978263855, 0.9691977500915527, 0.9701220393180847, 0.9715357422828674, 0.9720795154571533, 0.9715085625648499, 0.9739281535148621, 0.9726232290267944, 0.9742816090583801, 0.9740641117095947, 0.9735475778579712, 0.9727319478988647, 0.9743631482124329, 0.9741456508636475, 0.9736834764480591, 0.9757224917411804, 0.974417507648468, 0.9764293432235718, 0.9765924215316772, 0.9768099188804626, 0.9778158664703369, 0.9772449135780334, 0.9759399890899658, 0.9776527285575867, 0.9775711894035339, 0.9767012000083923, 0.977272093296051, 0.9765108823776245, 0.9768370985984802, 0.9782779812812805]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4o8dklhCN_oA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, AveragePooling1D, Flatten, Dense, Dropout, GlobalAveragePooling1D, Reshape, Multiply\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Squeeze-Excite block\n",
        "def squeeze_excite_block(input, ratio=16):\n",
        "    init = input\n",
        "    channel_axis = -1\n",
        "    filters = init.shape[channel_axis]\n",
        "    se_shape = (1, filters)\n",
        "\n",
        "    se = GlobalAveragePooling1D()(init)\n",
        "    se = Reshape(se_shape)(se)\n",
        "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "\n",
        "    x = Multiply()([init, se])\n",
        "    return x\n",
        "\n",
        "# MCSmini architecture\n",
        "def get_MCSmini(input_shape, num_classes):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv1D(32, kernel_size=3, padding='same', activation='relu')(input_layer)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = squeeze_excite_block(x)  # Add SE block after the first Conv1D layer\n",
        "    x = AveragePooling1D(pool_size=2)(x)\n",
        "\n",
        "    x = Conv1D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = squeeze_excite_block(x)  # Add SE block\n",
        "    x = AveragePooling1D(pool_size=2)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)  # Increase dropout to reduce overfitting\n",
        "\n",
        "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "    model.summary()  # To see the structure of your network\n",
        "    return model\n",
        "\n",
        "# Use the defined architecture to create the model\n",
        "eeg_input_shape = (window_size, 4)  # Adjusted to the correct number of channels\n",
        "num_classes = 2  # Assuming binary classification\n",
        "model = get_MCSmini(eeg_input_shape, num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ispoTcdSC3U4",
        "outputId": "a1e40b5a-68c1-4b9f-96b9-9929e7318fad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)        [(None, 1280, 4)]            0         []                            \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)          (None, 1280, 32)             416       ['input_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 1280, 32)             128       ['conv1d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling1d_1  (None, 32)                   0         ['batch_normalization_12[0][0]\n",
            " 2 (GlobalAveragePooling1D)                                         ']                            \n",
            "                                                                                                  \n",
            " reshape_12 (Reshape)        (None, 1, 32)                0         ['global_average_pooling1d_12[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_36 (Dense)            (None, 1, 2)                 64        ['reshape_12[0][0]']          \n",
            "                                                                                                  \n",
            " dense_37 (Dense)            (None, 1, 32)                64        ['dense_36[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)      (None, 1280, 32)             0         ['batch_normalization_12[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'dense_37[0][0]']            \n",
            "                                                                                                  \n",
            " average_pooling1d_12 (Aver  (None, 640, 32)              0         ['multiply_12[0][0]']         \n",
            " agePooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)          (None, 640, 64)              6208      ['average_pooling1d_12[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 640, 64)              256       ['conv1d_13[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling1d_1  (None, 64)                   0         ['batch_normalization_13[0][0]\n",
            " 3 (GlobalAveragePooling1D)                                         ']                            \n",
            "                                                                                                  \n",
            " reshape_13 (Reshape)        (None, 1, 64)                0         ['global_average_pooling1d_13[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_38 (Dense)            (None, 1, 4)                 256       ['reshape_13[0][0]']          \n",
            "                                                                                                  \n",
            " dense_39 (Dense)            (None, 1, 64)                256       ['dense_38[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)      (None, 640, 64)              0         ['batch_normalization_13[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'dense_39[0][0]']            \n",
            "                                                                                                  \n",
            " average_pooling1d_13 (Aver  (None, 320, 64)              0         ['multiply_13[0][0]']         \n",
            " agePooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " flatten_6 (Flatten)         (None, 20480)                0         ['average_pooling1d_13[0][0]']\n",
            "                                                                                                  \n",
            " dense_40 (Dense)            (None, 128)                  2621568   ['flatten_6[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 128)                  0         ['dense_40[0][0]']            \n",
            "                                                                                                  \n",
            " dense_41 (Dense)            (None, 2)                    258       ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2629474 (10.03 MB)\n",
            "Trainable params: 2629282 (10.03 MB)\n",
            "Non-trainable params: 192 (768.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Định nghĩa lại hàm get_model() để sử dụng get_MCSmini\n",
        "def get_model(input_shape, num_classes):\n",
        "    return get_MCSmini(input_shape, num_classes)\n",
        "\n",
        "# Khởi tạo biến kết quả\n",
        "val_res = {'accuracy': [], 'confusion_matrix': []}\n",
        "FOLD = 5\n",
        "nb_samples = data.shape[0]\n",
        "kfold = KFold(n_splits=FOLD, shuffle=True, random_state=42)  # K-fold Cross-Validation\n",
        "\n",
        "# Kích thước đầu vào dựa trên cấu hình của dữ liệu và số kênh đã chọn\n",
        "input_shape = (window_size, 4)  # 5 kênh như đã thảo luận\n",
        "\n",
        "# Huấn luyện mô hình trong mỗi fold\n",
        "for train_index, test_index in kfold.split(data):\n",
        "    X_train, X_test = data[train_index], data[test_index]\n",
        "    val_train, val_test = valence[train_index], valence[test_index]\n",
        "\n",
        "    # Tạo mô hình mới cho mỗi fold để tránh leak thông tin giữa các fold\n",
        "    model = get_model(input_shape, 2)  # Giả sử là phân loại nhị phân\n",
        "    history = model.fit(X_train, val_train, epochs=100, batch_size=256, shuffle=True)\n",
        "\n",
        "    # In kết quả huấn luyện\n",
        "    print(\"Training Loss:\", history.history['loss'][-1])\n",
        "    print(\"Training Accuracy:\", history.history['categorical_accuracy'][-1])\n",
        "\n",
        "    # Đánh giá mô hình trên tập kiểm tra\n",
        "    loss, accuracy = model.evaluate(X_test, val_test)\n",
        "    print(\"Test Loss:\", loss)\n",
        "    print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "    # Dự đoán và tính toán confusion matrix\n",
        "    pred = model.predict(X_test)\n",
        "    cm = confusion_matrix(val_test.argmax(axis=1), pred.argmax(axis=1))\n",
        "    val_res['accuracy'].append(accuracy)\n",
        "    val_res['confusion_matrix'].append(cm)\n",
        "    print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# Lưu kết quả vào file\n",
        "file_path = '/content/drive/MyDrive/DREAMER DATA/Process_Data/Dreamer_valenceMCSmini_' + str(eeg_band) + '.pkl'\n",
        "with open(file_path, 'wb') as f:\n",
        "    pkl.dump(val_res, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4qOvoII4Aw_l",
        "outputId": "f33c3dbc-ef71-4401-b187-8141af93fa7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_8 (InputLayer)        [(None, 1280, 4)]            0         []                            \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)          (None, 1280, 32)             416       ['input_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 1280, 32)             128       ['conv1d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling1d_1  (None, 32)                   0         ['batch_normalization_14[0][0]\n",
            " 4 (GlobalAveragePooling1D)                                         ']                            \n",
            "                                                                                                  \n",
            " reshape_14 (Reshape)        (None, 1, 32)                0         ['global_average_pooling1d_14[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_42 (Dense)            (None, 1, 2)                 64        ['reshape_14[0][0]']          \n",
            "                                                                                                  \n",
            " dense_43 (Dense)            (None, 1, 32)                64        ['dense_42[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)      (None, 1280, 32)             0         ['batch_normalization_14[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'dense_43[0][0]']            \n",
            "                                                                                                  \n",
            " average_pooling1d_14 (Aver  (None, 640, 32)              0         ['multiply_14[0][0]']         \n",
            " agePooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_15 (Conv1D)          (None, 640, 64)              6208      ['average_pooling1d_14[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 640, 64)              256       ['conv1d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling1d_1  (None, 64)                   0         ['batch_normalization_15[0][0]\n",
            " 5 (GlobalAveragePooling1D)                                         ']                            \n",
            "                                                                                                  \n",
            " reshape_15 (Reshape)        (None, 1, 64)                0         ['global_average_pooling1d_15[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_44 (Dense)            (None, 1, 4)                 256       ['reshape_15[0][0]']          \n",
            "                                                                                                  \n",
            " dense_45 (Dense)            (None, 1, 64)                256       ['dense_44[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)      (None, 640, 64)              0         ['batch_normalization_15[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'dense_45[0][0]']            \n",
            "                                                                                                  \n",
            " average_pooling1d_15 (Aver  (None, 320, 64)              0         ['multiply_15[0][0]']         \n",
            " agePooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " flatten_7 (Flatten)         (None, 20480)                0         ['average_pooling1d_15[0][0]']\n",
            "                                                                                                  \n",
            " dense_46 (Dense)            (None, 128)                  2621568   ['flatten_7[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, 128)                  0         ['dense_46[0][0]']            \n",
            "                                                                                                  \n",
            " dense_47 (Dense)            (None, 2)                    258       ['dropout_7[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2629474 (10.03 MB)\n",
            "Trainable params: 2629282 (10.03 MB)\n",
            "Non-trainable params: 192 (768.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "128/128 [==============================] - 7s 36ms/step - loss: 0.9087 - categorical_accuracy: 0.5549\n",
            "Epoch 2/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.6170 - categorical_accuracy: 0.6582\n",
            "Epoch 3/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.5452 - categorical_accuracy: 0.7205\n",
            "Epoch 4/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.4593 - categorical_accuracy: 0.7836\n",
            "Epoch 5/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.3568 - categorical_accuracy: 0.8466\n",
            "Epoch 6/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.2767 - categorical_accuracy: 0.8879\n",
            "Epoch 7/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.2140 - categorical_accuracy: 0.9147\n",
            "Epoch 8/100\n",
            "128/128 [==============================] - 5s 37ms/step - loss: 0.1809 - categorical_accuracy: 0.9293\n",
            "Epoch 9/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.1523 - categorical_accuracy: 0.9418\n",
            "Epoch 10/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.1336 - categorical_accuracy: 0.9496\n",
            "Epoch 11/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.1182 - categorical_accuracy: 0.9552\n",
            "Epoch 12/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.1122 - categorical_accuracy: 0.9579\n",
            "Epoch 13/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.1008 - categorical_accuracy: 0.9605\n",
            "Epoch 14/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0971 - categorical_accuracy: 0.9625\n",
            "Epoch 15/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0929 - categorical_accuracy: 0.9642\n",
            "Epoch 16/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0881 - categorical_accuracy: 0.9672\n",
            "Epoch 17/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0881 - categorical_accuracy: 0.9661\n",
            "Epoch 18/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0804 - categorical_accuracy: 0.9694\n",
            "Epoch 19/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0781 - categorical_accuracy: 0.9701\n",
            "Epoch 20/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0777 - categorical_accuracy: 0.9706\n",
            "Epoch 21/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0769 - categorical_accuracy: 0.9702\n",
            "Epoch 22/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0690 - categorical_accuracy: 0.9729\n",
            "Epoch 23/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0682 - categorical_accuracy: 0.9732\n",
            "Epoch 24/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0694 - categorical_accuracy: 0.9732\n",
            "Epoch 25/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0695 - categorical_accuracy: 0.9726\n",
            "Epoch 26/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0650 - categorical_accuracy: 0.9756\n",
            "Epoch 27/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0639 - categorical_accuracy: 0.9758\n",
            "Epoch 28/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0571 - categorical_accuracy: 0.9774\n",
            "Epoch 29/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0621 - categorical_accuracy: 0.9759\n",
            "Epoch 30/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0604 - categorical_accuracy: 0.9775\n",
            "Epoch 31/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0579 - categorical_accuracy: 0.9772\n",
            "Epoch 32/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0581 - categorical_accuracy: 0.9780\n",
            "Epoch 33/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0564 - categorical_accuracy: 0.9792\n",
            "Epoch 34/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0568 - categorical_accuracy: 0.9785\n",
            "Epoch 35/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0567 - categorical_accuracy: 0.9784\n",
            "Epoch 36/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0558 - categorical_accuracy: 0.9785\n",
            "Epoch 37/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0539 - categorical_accuracy: 0.9785\n",
            "Epoch 38/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0558 - categorical_accuracy: 0.9787\n",
            "Epoch 39/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0482 - categorical_accuracy: 0.9813\n",
            "Epoch 40/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0510 - categorical_accuracy: 0.9806\n",
            "Epoch 41/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0505 - categorical_accuracy: 0.9802\n",
            "Epoch 42/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0518 - categorical_accuracy: 0.9803\n",
            "Epoch 43/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0471 - categorical_accuracy: 0.9815\n",
            "Epoch 44/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0500 - categorical_accuracy: 0.9819\n",
            "Epoch 45/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0452 - categorical_accuracy: 0.9825\n",
            "Epoch 46/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0477 - categorical_accuracy: 0.9818\n",
            "Epoch 47/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0461 - categorical_accuracy: 0.9819\n",
            "Epoch 48/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0477 - categorical_accuracy: 0.9817\n",
            "Epoch 49/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0445 - categorical_accuracy: 0.9824\n",
            "Epoch 50/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0407 - categorical_accuracy: 0.9844\n",
            "Epoch 51/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0418 - categorical_accuracy: 0.9839\n",
            "Epoch 52/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0450 - categorical_accuracy: 0.9825\n",
            "Epoch 53/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0400 - categorical_accuracy: 0.9839\n",
            "Epoch 54/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0408 - categorical_accuracy: 0.9836\n",
            "Epoch 55/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0420 - categorical_accuracy: 0.9839\n",
            "Epoch 56/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0417 - categorical_accuracy: 0.9838\n",
            "Epoch 57/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0477 - categorical_accuracy: 0.9809\n",
            "Epoch 58/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0429 - categorical_accuracy: 0.9831\n",
            "Epoch 59/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0393 - categorical_accuracy: 0.9853\n",
            "Epoch 60/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0401 - categorical_accuracy: 0.9838\n",
            "Epoch 61/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0401 - categorical_accuracy: 0.9838\n",
            "Epoch 62/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0388 - categorical_accuracy: 0.9846\n",
            "Epoch 63/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0356 - categorical_accuracy: 0.9865\n",
            "Epoch 64/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0385 - categorical_accuracy: 0.9846\n",
            "Epoch 65/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0397 - categorical_accuracy: 0.9848\n",
            "Epoch 66/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0407 - categorical_accuracy: 0.9840\n",
            "Epoch 67/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0407 - categorical_accuracy: 0.9844\n",
            "Epoch 68/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0426 - categorical_accuracy: 0.9833\n",
            "Epoch 69/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0378 - categorical_accuracy: 0.9853\n",
            "Epoch 70/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0365 - categorical_accuracy: 0.9862\n",
            "Epoch 71/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0369 - categorical_accuracy: 0.9857\n",
            "Epoch 72/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0374 - categorical_accuracy: 0.9854\n",
            "Epoch 73/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0350 - categorical_accuracy: 0.9861\n",
            "Epoch 74/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0345 - categorical_accuracy: 0.9860\n",
            "Epoch 75/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0321 - categorical_accuracy: 0.9875\n",
            "Epoch 76/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0374 - categorical_accuracy: 0.9854\n",
            "Epoch 77/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0347 - categorical_accuracy: 0.9862\n",
            "Epoch 78/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0338 - categorical_accuracy: 0.9869\n",
            "Epoch 79/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0307 - categorical_accuracy: 0.9879\n",
            "Epoch 80/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0336 - categorical_accuracy: 0.9870\n",
            "Epoch 81/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0330 - categorical_accuracy: 0.9870\n",
            "Epoch 82/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0311 - categorical_accuracy: 0.9874\n",
            "Epoch 83/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0269 - categorical_accuracy: 0.9893\n",
            "Epoch 84/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0334 - categorical_accuracy: 0.9865\n",
            "Epoch 85/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0306 - categorical_accuracy: 0.9885\n",
            "Epoch 86/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0320 - categorical_accuracy: 0.9877\n",
            "Epoch 87/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0298 - categorical_accuracy: 0.9881\n",
            "Epoch 88/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0296 - categorical_accuracy: 0.9884\n",
            "Epoch 89/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0273 - categorical_accuracy: 0.9890\n",
            "Epoch 90/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0295 - categorical_accuracy: 0.9885\n",
            "Epoch 91/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0312 - categorical_accuracy: 0.9880\n",
            "Epoch 92/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0315 - categorical_accuracy: 0.9874\n",
            "Epoch 93/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0355 - categorical_accuracy: 0.9863\n",
            "Epoch 94/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0338 - categorical_accuracy: 0.9873\n",
            "Epoch 95/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0306 - categorical_accuracy: 0.9880\n",
            "Epoch 96/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0342 - categorical_accuracy: 0.9868\n",
            "Epoch 97/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0304 - categorical_accuracy: 0.9881\n",
            "Epoch 98/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0298 - categorical_accuracy: 0.9886\n",
            "Epoch 99/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0304 - categorical_accuracy: 0.9884\n",
            "Epoch 100/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.0295 - categorical_accuracy: 0.9874\n",
            "Training Loss: 0.02946840599179268\n",
            "Training Accuracy: 0.987429678440094\n",
            "256/256 [==============================] - 1s 4ms/step - loss: 1.5479 - categorical_accuracy: 0.6398\n",
            "Test Loss: 1.5479161739349365\n",
            "Test Accuracy: 0.639755368232727\n",
            "256/256 [==============================] - 1s 4ms/step\n",
            "Confusion Matrix:\n",
            " [[3270 1569]\n",
            " [1376 1960]]\n",
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)        [(None, 1280, 4)]            0         []                            \n",
            "                                                                                                  \n",
            " conv1d_16 (Conv1D)          (None, 1280, 32)             416       ['input_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 1280, 32)             128       ['conv1d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling1d_1  (None, 32)                   0         ['batch_normalization_16[0][0]\n",
            " 6 (GlobalAveragePooling1D)                                         ']                            \n",
            "                                                                                                  \n",
            " reshape_16 (Reshape)        (None, 1, 32)                0         ['global_average_pooling1d_16[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_48 (Dense)            (None, 1, 2)                 64        ['reshape_16[0][0]']          \n",
            "                                                                                                  \n",
            " dense_49 (Dense)            (None, 1, 32)                64        ['dense_48[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_16 (Multiply)      (None, 1280, 32)             0         ['batch_normalization_16[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'dense_49[0][0]']            \n",
            "                                                                                                  \n",
            " average_pooling1d_16 (Aver  (None, 640, 32)              0         ['multiply_16[0][0]']         \n",
            " agePooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_17 (Conv1D)          (None, 640, 64)              6208      ['average_pooling1d_16[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 640, 64)              256       ['conv1d_17[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling1d_1  (None, 64)                   0         ['batch_normalization_17[0][0]\n",
            " 7 (GlobalAveragePooling1D)                                         ']                            \n",
            "                                                                                                  \n",
            " reshape_17 (Reshape)        (None, 1, 64)                0         ['global_average_pooling1d_17[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_50 (Dense)            (None, 1, 4)                 256       ['reshape_17[0][0]']          \n",
            "                                                                                                  \n",
            " dense_51 (Dense)            (None, 1, 64)                256       ['dense_50[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_17 (Multiply)      (None, 640, 64)              0         ['batch_normalization_17[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'dense_51[0][0]']            \n",
            "                                                                                                  \n",
            " average_pooling1d_17 (Aver  (None, 320, 64)              0         ['multiply_17[0][0]']         \n",
            " agePooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " flatten_8 (Flatten)         (None, 20480)                0         ['average_pooling1d_17[0][0]']\n",
            "                                                                                                  \n",
            " dense_52 (Dense)            (None, 128)                  2621568   ['flatten_8[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, 128)                  0         ['dense_52[0][0]']            \n",
            "                                                                                                  \n",
            " dense_53 (Dense)            (None, 2)                    258       ['dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2629474 (10.03 MB)\n",
            "Trainable params: 2629282 (10.03 MB)\n",
            "Non-trainable params: 192 (768.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "128/128 [==============================] - 7s 36ms/step - loss: 0.9115 - categorical_accuracy: 0.5593\n",
            "Epoch 2/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.6217 - categorical_accuracy: 0.6561\n",
            "Epoch 3/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.5524 - categorical_accuracy: 0.7185\n",
            "Epoch 4/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.4653 - categorical_accuracy: 0.7811\n",
            "Epoch 5/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.3659 - categorical_accuracy: 0.8409\n",
            "Epoch 6/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.2826 - categorical_accuracy: 0.8823\n",
            "Epoch 7/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.2275 - categorical_accuracy: 0.9098\n",
            "Epoch 8/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.1871 - categorical_accuracy: 0.9255\n",
            "Epoch 9/100\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.1578 - categorical_accuracy: 0.9389\n",
            "Epoch 10/100\n",
            " 39/128 [========>.....................] - ETA: 3s - loss: 0.1338 - categorical_accuracy: 0.9507"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-94619f6066ca>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Tạo mô hình mới cho mỗi fold để tránh leak thông tin giữa các fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Giả sử là phân loại nhị phân\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# In kết quả huấn luyện\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f6MCWu8NwmOX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}